### training

1.**数据**

对与每张图片，需要进行如下数据处理：

图片进行缩放，使得长边小于等于1000，短边小于等于600（至少有一个等于）。

对相应的bounding boxes 也也进行同等尺度的缩放。

对于Caffe 的VGG16 预训练模型，需要图片位于0-255，BGR格式，并减去一个均值，使得图片像素的均值为0。

最后返回四个值供模型训练：

images ： 3×H×W ，BGR三通道，宽W，高H

bboxes： 4×K , K个bounding boxes，每个bounding box的左上角和右下角的座标，形如（Y\_min,X\_min, Y\_max,X\_max）,第Y行，第X列。

labels：K， 对应K个bounding boxes的label（对于VOC取值范围为\[0-19\]）

scale: 缩放的倍数, 原图H' ×W'被resize到了HxW（scale=H/H' ）

需要注意的是，目前大多数Faster R-CNN实现都只支持batch-size=1的训练

**2 Extractor**

Extractor使用的是预训练好的模型提取图片的特征。论文中主要使用的是Caffe的预训练模型VGG16。修改如下图所示：为了节省显存，前四层卷积层的学习率设为0。Conv5\_3的输出作为图片特征（feature）。conv5\_3相比于输入，下采样了16倍，也就是说输入的图片尺寸为3×H×W，那么feature的尺寸就是C×\(H/16\)×\(W/16\)。VGG最后的三层全连接层的前两层，一般用来初始化RoIHead的部分参数，这个我们稍后再讲。总之，一张图片，经过extractor之后，会得到一个C×\(H/16\)×\(W/16\)的feature map。



























reference:

https://www.jianshu.com/p/9da1f0756813

