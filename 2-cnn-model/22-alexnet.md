![](/assets/AlexNet.png)

在两个GPU上运行

**1. conv1层**

![](/assets/AlexNet_conv1.png)

1.1卷积层

输入图片：224\*224\*3

卷积核大小：kernel=11\*11\*3,step=4

卷积核种类：55

输出featuremap大小：55\*55          formula:（224-11+1）/4 +1

神经元数量：11\*11\*3 \* 96

训练参数：（11\*11+1）\*3 \*96（每个滤波器11\*11=121个unit参数和一个bias参数 \* 3 个 channel，一共96个滤波器）

连接数：（11\*11+1）\*3 \* 96 \* 55 \* 55

1.2 relu后：55\*55\*96

1.3 pool1 核：3\*3，步长：2，降采样后：27\*27\*96,   \(55-3\)/2+1

训练参数：2\*96（和的权+偏置）

norm1: local\_size = 5

**2. conv2**

![](/assets/AlexNet_conv2.png)

输入图片：27\*27\*3

卷积核大小：kernel=5\*5\*3,step=1,padding=2

卷积核种类：256

输出featuremap大小：27\*27        formula:（27-5+2\*2）/ 1 +1

神经元数量：5\*5\*3 \* 256

训练参数：（5\*5+1）\*3 \*256（每个滤波器5\*5=25个unit参数和一个bias参数 \* 3 个 channel，一共256个滤波器）

连接数：（5\*5+1）\*3 \* 256\* 27\* 27

1.2 relu后：27\*27\*256

1.3 pool2 核：3\*3，步长：2，降采样后：13\*13\*256,   \(27-3\)/2+1

训练参数：2\*256（和的权+偏置）

norm1: local\_size = 5

**3. conv3层**

![](/assets/AlexNet_conv3.png)

输入图片：13\*13\*256

卷积核大小：kernel=3\*3\*3,step=1,padding=2

卷积核种类：384

输出featuremap大小：13\*13   formula:（13 - 3 + 1\*2）/1 +1

神经元数量：3\*3\*3 \* 384

训练参数：（3\*3+1）\*3 \*384（每个滤波器3\*3=9个unit参数和一个bias参数 \* 3 个 channel，一共384个滤波器）

连接数：（3\*3+1）\*3 \* 384\* 13\* 13

**4. conv4层**

![](/assets/AlexNet_conv4.png)

输入图片：13\*13\*384

卷积核大小：kernel=3\*3\*3,step=1,padding=2

卷积核种类：384

输出featuremap大小：13\*13   formula:（13 - 3 + 1\*2）/1 +1

神经元数量：3\*3\*3 \* 384

训练参数：（3\*3+1）\*3 \*384（每个滤波器3\*3=9个unit参数和一个bias参数 \* 3 个 channel，一共384个滤波器）

连接数：（3\*3+1）\*3 \* 384\* 13\* 13

**5. conv5层**

![](/assets/AlexNet_conv5.png)

输入图片：13\*13\*3

卷积核大小：kernel=3\*3\*3,step=1,padding=1

卷积核种类：256

输出featuremap大小：13\*13    formula:（13-3+2\*1）/ 1 +1

神经元数量：3\*3\*3 \* 256

训练参数：（3\*3+1）\*3 \*256（每个滤波器3\*3=9个unit参数和一个bias参数 \* 3 个 channel，一共256个滤波器）

连接数：（3\*3+1）\*3 \* 256\* 13\* 13

1.2 relu后：13\*13\*256

1.3 pool5 核：3\*3，步长：2，降采样后：6\*6\*256,   \(13-3\)/2+1

训练参数：2\*256（和的权+偏置）

norm1: local\_size = 5

**6. F6层全连接层**

![](/assets/AlexNet_fc6.png)

输入：conv5输出

全连接-&gt;relu-&gt;dropout-&gt;输出4096维向量

计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过relu函数

可训练参数:4096\*\(256+1\)=1052672

1. F7全连接层

![](/assets/AlexNet_fc7.png)

全连接-&gt;relu-&gt;dropout-&gt;输出4096维向量

计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过relu函数

可训练参数:4096\*\(4096+1\)=16781312

7 F8全连接层

![](/assets/AlexNet_fc8.png)

全连接-&gt;relu-&gt;dropout-&gt;输出4096维向量

计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过relu函数

可训练参数:4096\*\(1000+1\)=4100096

