![](/assets/LeNet.png)LeNet-5共**有7层**，不包含输入，每层都包含可训练参数；每个层有**多个Feature Map**，每个FeatureMap通过一种卷积滤波器提取输入的一种特征，然后每个FeatureMap有**多个神经元。**

**1. C1层**是一个卷积层

输入图片：32\*32

卷积核大小：5\*5

卷积核种类：6

输出featuremap大小：28\*28 （32-5+1）

神经元数量：28\*28\*6

可训练参数：（5\*5+1）\*6（每个滤波器5\*5=25个unit参数和一个bias参数，一共6个滤波器）

连接数：（5\*5+1）\*6\*28\*28

**2. S2层是一个下采样层**

输入：28\*28

采样区域：2\*2

采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid

采样种类：6

输出featureMap大小：14\*14（28/2）

神经元数量：14\*14\*6

可训练参数：2\*6（和的权+偏置）

连接数：（2\*2+1）\*6\*14\*14

S2中每个特征图的大小是C1中特征图大小的1/4

**3. C3层也是一个卷积层**

输入：S2中所有6个或者几个特征map组合

卷积核大小：5\*5

卷积核种类：16

输出featureMap大小：10\*10

C3中的每个特征map是连接到S2中的所有6个或者几个特征map的，表示本层的特征map是上一层提取到的特征map的不同组合

存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入。

则：可训练参数：6\*（3\*25+1）+6\*（4\*25+1）+3\*（4\*25+1）+（25\*6+1）=1516

连接数：10\*10\*1516=151600

**4. S4层是一个下采样层**

输入：10\*10

采样区域：2\*2

采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid

采样种类：16

输出featureMap大小：5\*5（10/2）

神经元数量：5\*5\*16=400

可训练参数：2\*16=32（和的权+偏置）

连接数：16\*（2\*2+1）\*5\*5=2000

S4中每个特征图的大小是C3中特征图大小的1/4�

**5. C5层是一个卷积层**

输入：S4层的全部16个单元特征map（与s4全相连）

卷积核大小：5\*5

卷积核种类：120

输出featureMap大小：1\*1（5-5+1）

可训练参数/连接：120\*（16\*5\*5+1）=48120

**6. F6层全连接层**

输入：c5 120维向量

计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过sigmoid函数

可训练参数:84\*\(120+1\)=10164



